<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>MayNoe Scraper</title>
  <style>
    body {
      font-family: Arial, sans-serif;
      background-color: #2e7d32;
      color: white;
      margin: 5;
      padding: 0;
      display: flex;
      justify-content: center;
      align-items: center;
      height: 100vh;
    }
    .container {
      width: 800px;
      background: #e0f7e9;
      padding: 20px;
      border-radius: 15px;
      box-shadow: 0 4px 10px rgba(0, 0, 0, 0.1);
      text-align: center;
      color: #333;
    }
    h1 {
      font-size: 24px;
      font-weight: bold;
      margin-bottom: 20px;
      color: #1b5e20;
    }
    .input-group {
      margin-bottom: 20px;
    }
    .input-group label {
      font-size: 16px;
      font-weight: bold;
      color: #1b5e20;
    }
    .input-group input {
      width: 100px;
      padding: 5px;
      border-radius: 4px;
      border: 1px solid #2e7d32;
      margin-left: 10px;
      text-align: center;
    }
    .button-group {
      display: flex;
      justify-content: center;
      gap: 20px;
      margin-bottom: 20px;
    }
    button {
      background-color: #2e7d32;
      color: white;
      padding: 10px 20px;
      border: none;
      border-radius: 8px;
      cursor: pointer;
      font-size: 16px;
    }
    button:hover {
      background-color: #1b5e20;
    }
    .output {
      margin-top: 20px;
    }
    textarea {
      width: 100%;
      height: 220px;
      padding: 0px;
      border: 2px solid #2e7d32;
      border-radius: 8px;
      font-family: monospace;
      font-size: 14px;
      background: #f7fff7;
      color: #333;
    }
  </style>
</head>
<body>
  <div class="container">
    <h1>MayNoe.com Scrape Data</h1>
    <div class="input-group">
      <label for="page-count-start">Start of Pages:</label>
      <input type="number" id="page-count-start" min="1" max="1000" value="1">
     </div>
     
         <div class="input-group">
 <label for="page-count-end">End of  Pages  :</label>
      <input type="number" id="page-count-end" min="1" max="1000" value="10">
      	
    </div>
    <div class="button-group">
      <button onclick="scrapeMultiplePages()">Scrape Data</button>
      <button onclick="copyJson()">JSON Copy</button>
    </div>
    <div class="output">
      <textarea id="json-output" readonly></textarea>
    </div>
  </div>

  <script>
    async function scrapePage(url) {
      const proxyUrl = 'https://api.allorigins.win/get?url=' + encodeURIComponent(url);
      try {
        const response = await fetch(proxyUrl);
        const data = await response.json();
        const html = data.contents;

        const parser = new DOMParser();
        const doc = parser.parseFromString(html, 'text/html');
        const items = doc.querySelectorAll('.clean-grid-grid-post-thumbnail');

        const pageData = [];
        items.forEach(item => {
          const linkElement = item.querySelector('a');
          const imgElement = item.querySelector('img');

          const title = linkElement.getAttribute('title').replace('Permanent Link to ', '');
          const image = imgElement.getAttribute('src');
          const href = linkElement.getAttribute('href');

          pageData.push({
            title: title,
            image: image,
            link: `https://zindown.github.io/maynoeplayer.html?url=${href}`,
            type: 'web'
          });
        });

        return pageData;
      } catch (error) {
        console.error(`Failed to scrape ${url}:`, error);
        return [];
      }
    }

    async function scrapeMultiplePages() {
      const startPage = parseInt(document.getElementById('page-count-start').value, 10) || 1;
      const endPage = parseInt(document.getElementById('page-count-end').value, 10) || 10;
      const baseUrl = 'https://maynoe.com/page/';
      const allData = [];

      for (let i = startPage; i <= endPage; i++) {
        const pageUrl = `${baseUrl}${i}/`;
        console.log(`Scraping: ${pageUrl}`);
        const pageData = await scrapePage(pageUrl);
        allData.push(...pageData); // Merge data from each page
      }

      // Display the combined JSON data
      const jsonOutput = document.getElementById('json-output');
      jsonOutput.value = JSON.stringify({ apyar: allData }, null, 2);
    }

    function copyJson() {
      const jsonOutput = document.getElementById('json-output');
      if (jsonOutput.value.trim() === "") {
        alert('No data to copy. Please scrape the data first.');
        return;
      }

      navigator.clipboard.writeText(jsonOutput.value)
        .then(() => {
          alert('JSON copied to clipboard!');
          jsonOutput.value = ""; // Clear the JSON content after copying
        })
        .catch(() => alert('Failed to copy JSON.'));
    }
  </script>
</body>
</html>
